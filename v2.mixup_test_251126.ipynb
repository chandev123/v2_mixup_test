{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c82433",
   "metadata": {},
   "source": [
    "v2.mixup_test_251126.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db152fee",
   "metadata": {},
   "source": [
    "목표: v2.mixup의 기능 확인\n",
    "과제: v2.mixup이 이미지를 섞는 연산 확인\n",
    "- v2.mixup이 이미지와 라벨을 섞는 기능 확인\n",
    "- v2.mixup을 통과한 결과가 손실함수에 반영되는 기능 확인\n",
    "- v2.mixup을 통과한 결과가 optimizer에 반영되는 기능 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "# 커스텀 데이터셋 클래스\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, train=True):\n",
    "        self.train = train\n",
    "        train_df = pd.read_csv(cvs_path)\n",
    "\n",
    "        self.name2label = dict(zip(train_df[\"name\"], train_df[\"label\"]))\n",
    "\n",
    "        if self.train:\n",
    "            self.img_path = glob(f\"{data_path}/train_data/*.png\")\n",
    "            self.labels =  [self.name2label[d.split(\"/\")[-1]] for d in self.img_path]\n",
    "        else:\n",
    "            self.img_path = glob(f\"{data_path}/test_data/*.png\")\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)   \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index])\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.train:\n",
    "            return img, self.labels[index]\n",
    "        else:\n",
    "            return img, self.img_path[index].split(\"/\")[-1]\n",
    "\n",
    "# 데이터셋 디렉토리 위치 지정\n",
    "data_f_path = Path.cwd()\n",
    "data_path = data_f_path.joinpath(\"v2.mixup_test_251126_png\")\n",
    "cvs_path = data_path.joinpath(\"train_data.csv\")\n",
    "\n",
    "transform =  v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(dtype=torch.float32, scale=True),\n",
    "    v2.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "test_transform =  v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(dtype=torch.long)\n",
    "])\n",
    "\n",
    "train_data = MyDataset(data_path, train=True, transform=transform)\n",
    "test_data = MyDataset(data_path, train=False, transform=test_transform)\n",
    "\n",
    "train_size = int(len(train_data) * 0.9)\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [train_size, len(train_data) - train_size])\n",
    "train_data, train_vl_data = torch.utils.data.random_split(train_data, [train_size, len(train_data) - train_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "train_vl_loader = torch.utils.data.DataLoader(train_vl_data, batch_size=128, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=128, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b98ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import GradScaler\n",
    "model = resnet18(pretrained=False)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.fc = nn.Linear(512, 10, bias=True)\n",
    "model = model.to(device)\n",
    "\n",
    "scaler = GradScaler()\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=100, eta_min=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 함수\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()                 \n",
    "    tot_loss, tot_acc, tot_cnt = 0.0, 0.0, 0\n",
    "\n",
    "    pbar = tqdm(loader, desc='훈련')\n",
    "    for i, (x, y) in enumerate(pbar):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x, y = mixup(x, y)\n",
    "        optimizer.zero_grad()              \n",
    "        with autocast(device_type=device): \n",
    "            out = model(x)         \n",
    "            loss = criterion(out, y)    \n",
    "        scaler.scale(loss).backward()           \n",
    "        scaler.step(optimizer)          \n",
    "        scaler.update()\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step()                  \n",
    "\n",
    "        tot_loss += loss.item() * y.size(0)\n",
    "        pred = torch.sigmoid(out) >= 0.5\n",
    "        y_true = y >= 0.5\n",
    "        tot_acc += (pred == y_true).all(dim=1).sum().item()  \n",
    "        tot_cnt  += y.size(0)\n",
    "\n",
    "        pbar.set_postfix({'LR': current_lr})\n",
    "\n",
    "    return tot_loss/tot_cnt, tot_acc/tot_cnt, current_lr\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    tot_loss, tot_acc, tot_cnt = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y = F.one_hot(y, num_classes=21).float()\n",
    "            \n",
    "            with autocast(device_type=device):\n",
    "                out = model(x)\n",
    "                loss = criterion(out, y)\n",
    "\n",
    "            tot_loss += loss.item() * y.size(0)\n",
    "            pred = torch.sigmoid(out) >= 0.5\n",
    "            y_true = y >= 0.5\n",
    "            tot_acc += (pred == y_true).all(dim=1).sum().item()  \n",
    "            tot_cnt  += y.size(0)\n",
    "\n",
    "    return tot_loss/tot_cnt, tot_acc/tot_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e5b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_X = np.zeros(len(y_tensor))\n",
    "\n",
    "for fold, (train_i, val_i) in enumerate(rskf.split(dummy_X, y_tensor)):\n",
    "    print('')\n",
    "\n",
    "\n",
    "    tr_dataset = MySubset(train_ten, train_i, transform=aug)\n",
    "    vl_dataset = MySubset(train_ten, val_i)\n",
    "\n",
    "    tr = DataLoader(tr_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    vl = DataLoader(vl_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    tr_hist, te_hist, lr_hist = [], [], []\n",
    "    te_loss, best_te_loss, patience_counter = 0, 0, 0\n",
    "    for ep in range(1, 5):\n",
    "        tr_loss, tr_acc, current_lr = train_one_epoch(model, tr, optimizer, criterion) # tr\n",
    "        te_loss, te_acc = evaluate(model, vl, criterion) # va\n",
    "\n",
    "        tr_hist.append((tr_loss, tr_acc))\n",
    "        te_hist.append((te_loss, te_acc))\n",
    "        lr_hist.append(current_lr)\n",
    "\n",
    "            if te_loss < best_te_loss:\n",
    "                best_te_loss = te_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= 3:\n",
    "                print(f\"Early stopping at epoch {ep}\")\n",
    "                break\n",
    "\n",
    "    print('학습완료')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
