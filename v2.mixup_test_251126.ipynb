{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c82433",
   "metadata": {},
   "source": [
    "v2.mixup_test_251126.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db152fee",
   "metadata": {},
   "source": [
    "목표: v2.mixup의 기능 확인\n",
    "과제: v2.mixup이 이미지를 섞는 연산 확인\n",
    "- v2.mixup이 이미지와 라벨을 섞는 기능 확인\n",
    "- v2.mixup을 통과한 결과가 손실함수에 반영되는 기능 확인\n",
    "- v2.mixup을 통과한 결과가 optimizer에 반영되는 기능 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 데이터셋 클래스\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, train=True):\n",
    "        self.train = train\n",
    "        train_df = pd.read_csv(cvs_path)\n",
    "        self.name2label = dict(zip(train_df[\"name\"], train_df[\"label\"]))\n",
    "\n",
    "        if self.train:\n",
    "            self.img_path = list(data_path.joinpath(\"train_data\").rglob( \"*.png\"))\n",
    "            self.labels =  [self.name2label[d.name] for d in self.img_path]\n",
    "        else:\n",
    "            self.img_path = list(data_path.joinpath(\"test_data\").rglob(\"*.png\"))\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)   \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index])\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.train:\n",
    "            return img, self.labels[index]\n",
    "        else:\n",
    "            return img, self.img_path[index].name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a9d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 디렉토리 위치 지정\n",
    "data_dir = Path.cwd()\n",
    "data_path = data_dir.joinpath(\"v2.mixup_test_251126_png\")\n",
    "cvs_path = data_path.joinpath(\"train_data.csv\")\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform =  v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(dtype=torch.float32, scale=True),\n",
    "    v2.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "test_transform =  v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(dtype=torch.long)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4821a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MyDataset(data_path, train=True, transform=transform)\n",
    "test_data = MyDataset(data_path, train=False, transform=test_transform)\n",
    "\n",
    "train_size = int(len(train_data) * 0.8)\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [train_size, len(train_data) - train_size])\n",
    "train_data, train_vl_data = torch.utils.data.random_split(train_data, [train_size, len(train_data) - train_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "train_vl_loader = torch.utils.data.DataLoader(train_vl_data, batch_size=128, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=128, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b98ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MARKCH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MARKCH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\MARKCH\\AppData\\Local\\Temp\\ipykernel_7580\\3840461923.py:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(pretrained=False)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.fc = nn.Linear(512, 10, bias=True)\n",
    "model = model.to(device)\n",
    "\n",
    "scaler = GradScaler()\n",
    "# criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=0.001)\n",
    "mixup = v2.MixUp(alpha=0.2, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 함수\n",
    "def train_one_epoch(model, loader):\n",
    "    model.train()                 \n",
    "    tot_loss, tot_acc, tot_cnt = 0.0, 0.0, 0\n",
    "\n",
    "    pbar = tqdm(loader, desc='훈련')\n",
    "    for i, (x, y) in enumerate(pbar):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x, y = mixup(x, y)\n",
    "        optimizer.zero_grad()              \n",
    "\n",
    "        out = model(x)         \n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()           \n",
    "        optimizer.step()          \n",
    "        scheduler.step()                  \n",
    "\n",
    "        tot_loss += loss.item() * y.size(0)\n",
    "        # pred = torch.sigmoid(out) >= 0.5\n",
    "        # y_true = y >= 0.5\n",
    "        # tot_acc += (pred == y_true).all(dim=1).sum().item()  \n",
    "        tot_cnt  += y.size(0)\n",
    "\n",
    "    return tot_loss/tot_cnt, tot_acc/tot_cnt\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    tot_loss, tot_acc, tot_cnt = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y = F.one_hot(y, num_classes=10).float()\n",
    "            \n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            tot_loss += loss.item() * y.size(0)\n",
    "            # pred = torch.sigmoid(out) >= 0.5\n",
    "            # y_true = y >= 0.5\n",
    "            # tot_acc += (pred == y_true).all(dim=1).sum().item()  \n",
    "            tot_cnt  += y.size(0)\n",
    "\n",
    "    return tot_loss/tot_cnt, tot_acc/tot_cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8e5b8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "훈련: 100%|██████████| 32/32 [00:17<00:00,  1.79it/s]\n",
      "훈련: 100%|██████████| 32/32 [00:15<00:00,  2.01it/s]\n",
      "훈련: 100%|██████████| 32/32 [00:15<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 3\n",
      "학습완료\n"
     ]
    }
   ],
   "source": [
    "tr_hist, te_hist, lr_hist = [], [], []\n",
    "te_loss, best_te_loss, patience_counter = 0, 0, 0\n",
    "for ep in range(1, 6):\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_loader) # tr\n",
    "    te_loss, te_acc = evaluate(model, val_loader) # va\n",
    "\n",
    "    tr_hist.append((tr_loss, tr_acc))\n",
    "    te_hist.append((te_loss, te_acc))\n",
    "\n",
    "    if te_loss < best_te_loss:\n",
    "        best_te_loss = te_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= 3:\n",
    "        print(f\"Early stopping at epoch {ep}\")\n",
    "        break\n",
    "\n",
    "print('학습완료')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
