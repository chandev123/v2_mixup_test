{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c82433",
   "metadata": {},
   "source": [
    "v2.mixup_test_251126.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db152fee",
   "metadata": {},
   "source": [
    "목표: v2.mixup의 기능 확인\n",
    "과제: v2.mixup이 이미지를 섞는 연산 확인\n",
    "- v2.mixup이 이미지와 라벨을 섞는 기능 확인\n",
    "- v2.mixup을 통과한 결과가 손실함수에 반영되는 기능 확인\n",
    "- v2.mixup을 통과한 결과가 optimizer에 반영되는 기능 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 데이터셋 클래스\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, train=True):\n",
    "        self.train = train\n",
    "        train_df = pd.read_csv(cvs_path)\n",
    "        self.name2label = dict(zip(train_df[\"name\"], train_df[\"label\"]))\n",
    "\n",
    "        if self.train:\n",
    "            self.img_path = list(data_path.joinpath(\"train_data\").rglob( \"*.png\"))\n",
    "            self.labels =  [self.name2label[d.name] for d in self.img_path]\n",
    "        else:\n",
    "            self.img_path = list(data_path.joinpath(\"test_data\").rglob(\"*.png\"))\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)   \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index])\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.train:\n",
    "            return img, self.labels[index]\n",
    "        else:\n",
    "            return img, self.img_path[index].name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a9d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 디렉토리 위치 지정\n",
    "data_dir = Path.cwd()\n",
    "data_path = data_dir.joinpath(\"v2.mixup_test_251126_png\")\n",
    "cvs_path = data_path.joinpath(\"train_data.csv\")\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform =  v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(dtype=torch.float32, scale=True),\n",
    "    v2.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "test_transform =  v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(dtype=torch.long)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4821a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MyDataset(data_path, train=True, transform=transform)\n",
    "test_data = MyDataset(data_path, train=False, transform=test_transform)\n",
    "\n",
    "train_size = int(len(train_data) * 0.8)\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [train_size, len(train_data) - train_size])\n",
    "train_data, train_vl_data = torch.utils.data.random_split(train_data, [train_size, len(train_data) - train_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "train_vl_loader = torch.utils.data.DataLoader(train_vl_data, batch_size=128, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=128, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b98ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MARKCH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MARKCH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\MARKCH\\AppData\\Local\\Temp\\ipykernel_7580\\3840461923.py:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(pretrained=False)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.fc = nn.Linear(512, 10, bias=True)\n",
    "model = model.to(device)\n",
    "\n",
    "scaler = GradScaler()\n",
    "# criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=0.001)\n",
    "mixup = v2.MixUp(alpha=0.2, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf79a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 함수\n",
    "def train_one_epoch(model, loader):\n",
    "    model.train()                 \n",
    "    tot_loss, tot_acc, tot_cnt = 0.0, 0.0, 0\n",
    "\n",
    "    pbar = tqdm(loader, desc='훈련')\n",
    "    for i, (x, y) in enumerate(pbar):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x, y = mixup(x, y)\n",
    "        optimizer.zero_grad()              \n",
    "\n",
    "        out = model(x)         \n",
    "        loss = criterion(out, y)    \n",
    "        loss.backward()           \n",
    "        optimizer.step()          \n",
    "        scheduler.step()                  \n",
    "\n",
    "        tot_loss += loss.item() * y.size(0)\n",
    "        # pred = torch.sigmoid(out) >= 0.5\n",
    "        # y_true = y >= 0.5\n",
    "        # tot_acc += (pred == y_true).all(dim=1).sum().item()  \n",
    "        tot_cnt  += y.size(0)\n",
    "\n",
    "    return tot_loss/tot_cnt, tot_acc/tot_cnt\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    tot_loss, tot_acc, tot_cnt = 0.0, 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y = F.one_hot(y, num_classes=10).float()\n",
    "            \n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            tot_loss += loss.item() * y.size(0)\n",
    "            # pred = torch.sigmoid(out) >= 0.5\n",
    "            # y_true = y >= 0.5\n",
    "            # tot_acc += (pred == y_true).all(dim=1).sum().item()  \n",
    "            tot_cnt  += y.size(0)\n",
    "\n",
    "    return tot_loss/tot_cnt, tot_acc/tot_cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e5b8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "훈련: 100%|██████████| 32/32 [00:27<00:00,  1.17it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([128, 21])) must be the same as input size (torch.Size([128, 10]))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m6\u001b[39m):\n\u001b[32m      4\u001b[39m     tr_loss, tr_acc = train_one_epoch(model, train_loader) \u001b[38;5;66;03m# tr\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     te_loss, te_acc = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# va\u001b[39;00m\n\u001b[32m      7\u001b[39m     tr_hist.append((tr_loss, tr_acc))\n\u001b[32m      8\u001b[39m     te_hist.append((te_loss, te_acc))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(model, loader)\u001b[39m\n\u001b[32m     32\u001b[39m y = F.one_hot(y, num_classes=\u001b[32m21\u001b[39m).float()\n\u001b[32m     34\u001b[39m out = model(x)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m tot_loss += loss.item() * y.size(\u001b[32m0\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# pred = torch.sigmoid(out) >= 0.5\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# y_true = y >= 0.5\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# tot_acc += (pred == y_true).all(dim=1).sum().item()  \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MARKCH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MARKCH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MARKCH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:821\u001b[39m, in \u001b[36mBCEWithLogitsLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m    820\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m821\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MARKCH\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\functional.py:3639\u001b[39m, in \u001b[36mbinary_cross_entropy_with_logits\u001b[39m\u001b[34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[39m\n\u001b[32m   3636\u001b[39m     reduction_enum = _Reduction.get_enum(reduction)\n\u001b[32m   3638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target.size() == \u001b[38;5;28minput\u001b[39m.size()):\n\u001b[32m-> \u001b[39m\u001b[32m3639\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3640\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget.size()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.size()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3641\u001b[39m     )\n\u001b[32m   3643\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.binary_cross_entropy_with_logits(\n\u001b[32m   3644\u001b[39m     \u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum\n\u001b[32m   3645\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: Target size (torch.Size([128, 21])) must be the same as input size (torch.Size([128, 10]))"
     ]
    }
   ],
   "source": [
    "tr_hist, te_hist, lr_hist = [], [], []\n",
    "te_loss, best_te_loss, patience_counter = 0, 0, 0\n",
    "for ep in range(1, 6):\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_loader) # tr\n",
    "    te_loss, te_acc = evaluate(model, val_loader) # va\n",
    "\n",
    "    tr_hist.append((tr_loss, tr_acc))\n",
    "    te_hist.append((te_loss, te_acc))\n",
    "\n",
    "    if te_loss < best_te_loss:\n",
    "        best_te_loss = te_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= 3:\n",
    "        print(f\"Early stopping at epoch {ep}\")\n",
    "        break\n",
    "\n",
    "print('학습완료')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
